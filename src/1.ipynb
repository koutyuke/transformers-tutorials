{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.1 文書分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/transformers-tutorials/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'positive', 'score': 0.9993619322776794}\n"
     ]
    }
   ],
   "source": [
    "text_classification_pipeline = pipeline(model=\"llm-book/bert-base-japanese-v3-marc_ja\")\n",
    "positive_text = \"世界には言葉がわからなくても感動する音楽がある。\"\n",
    "\n",
    "# positive_textの極性を予測\n",
    "print(text_classification_pipeline(positive_text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'negative', 'score': 0.9855380058288574}\n"
     ]
    }
   ],
   "source": [
    "negative_text = \"世界には言葉に出ないほどひどい音楽がある。\"\n",
    "print(text_classification_pipeline(negative_text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.2 自然言語推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'entailment', 'score': 0.9977477192878723}\n"
     ]
    }
   ],
   "source": [
    "nli_pipeline = pipeline(model=\"llm-book/bert-base-japanese-v3-jnli\")\n",
    "text = \"二人の男性がジェット機を見ています。\"\n",
    "entailment_text = \"ジェット機を見ている二人の男性がいます。\"\n",
    "\n",
    "# 理論関係を予測\n",
    "print(nli_pipeline({\"text\": text, \"text_pair\": entailment_text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'neutral', 'score': 0.9984857439994812}\n"
     ]
    }
   ],
   "source": [
    "contradiction_text = \"二人の男性がが飛んでいます。\"\n",
    "\n",
    "# 矛盾関係を予測\n",
    "print(nli_pipeline({\"text\": text, \"text_pair\": contradiction_text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'neutral', 'score': 0.9976142644882202}\n"
     ]
    }
   ],
   "source": [
    "neutral_text = \"二人の男性が、白い飛行機を眺めています。\"\n",
    "\n",
    "# 中立関係を予測\n",
    "print(nli_pipeline({\"text\": text, \"text_pair\": neutral_text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.3 意味的類似度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8350539207458496\n"
     ]
    }
   ],
   "source": [
    "text_slim_pipeline = pipeline(model=\"llm-book/bert-base-japanese-v3-jsts\", function_to_apply=\"none\")\n",
    "\n",
    "text = \"川縁でサーフを持った人たちがいます。\"\n",
    "sim_text = \"サーファーたちが川縁に立っています。\"\n",
    "\n",
    "# 類似度を予測\n",
    "result = text_slim_pipeline({\"text\": text, \"text_pair\": sim_text})\n",
    "print(result[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04958426207304001\n"
     ]
    }
   ],
   "source": [
    "dissim_text = \"トイレの壁に黒いタオルがかけられています。\"\n",
    "\n",
    "# 類似度を予測\n",
    "result = text_slim_pipeline({\"text\": text, \"text_pair\": dissim_text})\n",
    "print(result[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8406088352203369\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "sim_enc_pipeline = pipeline(model=\"llm-book/bert-base-japanese-v3-unsup-simcse-jawiki\", task=\"feature-extraction\")\n",
    "\n",
    "# ベクトルの取得\n",
    "text_emb = sim_enc_pipeline(text, return_tensors=True)[0][0]\n",
    "sim_emb = sim_enc_pipeline(sim_text, return_tensors=True)[0][0]\n",
    "\n",
    "# コサイン類似度を計算\n",
    "sim_pair_score = cosine_similarity(text_emb, sim_emb, dim=0)\n",
    "print(sim_pair_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3928905725479126\n"
     ]
    }
   ],
   "source": [
    "# ベクトルの取得\n",
    "dissim_emb = sim_enc_pipeline(dissim_text, return_tensors=True)[0][0]\n",
    "\n",
    "# コサイン類似度を計算\n",
    "dissim_pair_score = cosine_similarity(text_emb, dissim_emb, dim=0)\n",
    "print(dissim_pair_score.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.4 固有表現認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': None,\n",
      "  'entity_group': '人名',\n",
      "  'score': np.float32(0.99823624),\n",
      "  'start': None,\n",
      "  'word': '大谷 翔平'},\n",
      " {'end': None,\n",
      "  'entity_group': '地名',\n",
      "  'score': np.float32(0.9986874),\n",
      "  'start': None,\n",
      "  'word': '岩手 県 水沢 市'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "ner_pipeline = pipeline(model=\"llm-book/bert-base-japanese-v3-ner-wikipedia-dataset\", aggregation_strategy=\"simple\")\n",
    "\n",
    "text = \"大谷翔平は岩手県水沢市出身のプロ野球選手\"\n",
    "\n",
    "# 固有表現抽出\n",
    "pprint(ner_pipeline(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.5 要約生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'今夜はNHKスペシャル「世界を変えた男 スティーブ・ジョブズ」をチェック!'\n"
     ]
    }
   ],
   "source": [
    "text2text_pipeline = pipeline(model=\"llm-book/t5-base-long-livedoor-news-corpus\")\n",
    "\n",
    "article = \"ついに始まった３連休。テレビを見ながら過ごしている人も多いのではないだろうか？　今夜オススメなのは何と言っても、NHKスペシャル「世界を変えた男 スティーブ・ジョブズ」だ。実は知らない人も多いジョブズ氏の養子に出された生い立ちや、アップル社から一時追放されるなどの経験。そして、彼が追い求めた理想の未来とはなんだったのか、ファンならずとも気になる内容になっている。 今年、亡くなったジョブズ氏の伝記は日本でもベストセラーになっている。今後もアップル製品だけでなく、世界でのジョブズ氏の影響は大きいだろうと想像される。ジョブズ氏のことをあまり知らないという人もこの機会にぜひチェックしてみよう。 世界を変えた男　スティーブ・ジョブズ（NHKスペシャル）\"\n",
    "\n",
    "# 要約を生成\n",
    "pprint(text2text_pipeline(article)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 transformersの基本的な使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁', '今日', 'は', '天気', 'が', 'いい', 'の', 'で']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"abeja/gpt2-large-japanese\")\n",
    "\n",
    "tokenizer.tokenize(\"今日は天気がいいので\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日は天気がいいので外でお弁当を食べました\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"abeja/gpt2-large-japanese\")\n",
    "\n",
    "inputs = tokenizer(\"今日は天気がいいので\", return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=15, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
